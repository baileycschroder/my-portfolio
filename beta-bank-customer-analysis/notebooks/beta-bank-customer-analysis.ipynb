{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "  <b>Overall Summary of the Project ‚Äì Iteration 3</b><br><br>\n",
    "\n",
    "  Hi Bailey, I‚Äôm <b>Victor Camargo</b>. I‚Äôve reviewed your code and you did a great job ‚Äî it's clean, well-organized, and shows a solid understanding of the modeling workflow.\n",
    "\n",
    "  <b>Nice work on:</b><br>\n",
    "  ‚úîÔ∏è Preparing and preprocessing the data with appropriate feature handling<br>\n",
    "  ‚úîÔ∏è Exploring and addressing class imbalance with two valid techniques<br>\n",
    "  ‚úîÔ∏è Evaluating models using both F1 and AUC-ROC as required by the task<br>\n",
    "  ‚úîÔ∏è Following up on previous feedback and successfully applying hyperparameter tuning to reach the 0.59 F1 score threshold<br><br>\n",
    "\n",
    "  ‚úÖ Project approved\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "  <b>Overall Summary of the Project ‚Äì Iteration 2</b><br><br>\n",
    "\n",
    "  Hi Bailey, I‚Äôm <b>Victor Camargo</b>. I‚Äôve reviewed your code and you did a great job ‚Äî it's clean, well-organized, and shows a solid understanding of the modeling workflow.\n",
    "\n",
    "  <b>Nice work on:</b><br>\n",
    "  ‚úîÔ∏è Preparing and preprocessing the data with appropriate feature handling<br>\n",
    "  ‚úîÔ∏è Exploring and addressing class imbalance with two valid techniques<br>\n",
    "  ‚úîÔ∏è Evaluating models using both F1 and AUC-ROC as required by the task<br><br>\n",
    "\n",
    "  A few things still need your attention before approval:<br>\n",
    "  üî¥ Consider applying hyperparameter tuning to a model trained on an upsampled dataset, which might push your performance over the line<br>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "  <b>Overall Summary of the Project ‚Äì Iteration 1</b><br><br>\n",
    "\n",
    "  Hi Bailey, I‚Äôm <b>Victor Camargo</b>. I‚Äôll be reviewing your project and sharing feedback using the color-coded comments below. Your code is clean and well-organized, and you‚Äôve demonstrated a solid understanding of the modeling workflow. Nice work overall.\n",
    "\n",
    "  <b>Nice work on:</b><br>\n",
    "  ‚úîÔ∏è Preparing and preprocessing the data with appropriate feature handling<br>\n",
    "  ‚úîÔ∏è Exploring and addressing class imbalance with two valid techniques<br>\n",
    "  ‚úîÔ∏è Evaluating models using both F1 and AUC-ROC as required by the task<br><br>\n",
    "\n",
    "  A few things still need your attention before approval:<br>\n",
    "  üî¥ The final F1 score on the test set is just below the required 0.59 threshold<br>\n",
    "  üî¥ The conclusion needs to be updated to reflect the test set results accurately and avoid overstatement<br><br>\n",
    "\n",
    "  <hr>\n",
    "\n",
    "  üîπ <b>Legend:</b><br>\n",
    "  üü¢ Green = well done<br>\n",
    "  üü° Yellow = suggestions<br>\n",
    "  üî¥ Red = must fix<br>\n",
    "  üîµ Blue = your comments or questions<br><br>\n",
    "\n",
    "  Please make sure all cells run smoothly from top to bottom and produce outputs before submitting. Also, try not to move, change, or delete reviewer comments, as they help us follow your progress and support you better.<br><br>\n",
    "\n",
    "  <b>Feel free to reach out if you need help in Questions channel.</b><br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the churn dataset, dropped non-informative columnsand filled missing values in the 'Tenure' column using the median. Categorical features 'Gender' and 'Geography' were encoded using Label Encoding. Data split into training, validation, and test sets using stratification to preserve class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  The import section is well-structured and includes all the essential libraries for data processing, visualization, and modeling. Good start to the project.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/Churn.csv') \n",
    "\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "df['Tenure'].fillna(df['Tenure'].median(), inplace=True)\n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "df['Gender'] = le_gender.fit_transform(df['Gender'])\n",
    "\n",
    "le_geo = LabelEncoder()\n",
    "df['Geography'] = le_geo.fit_transform(df['Geography'])\n",
    "\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examined the target variable ('Exited') and observed significant imbalance, 80% customers stayed and 20% customers churned. This imbalance can bias models toward predicitng the majority class, so I evaluated performance without correction first then applied balancing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  The data loading and preprocessing steps are clearly implemented. You correctly removed non-informative columns, filled missing values in the <code>Tenure</code> column using the median, and applied label encoding to categorical features. Everything looks well-structured and appropriate for the task.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline F1 Score: 0.562111801242236\n",
      "Baseline AUC-ROC: 0.851123851123851\n"
     ]
    }
   ],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)\n",
    "\n",
    "baseline_model = RandomForestClassifier(random_state=42)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = baseline_model.predict(X_valid)\n",
    "y_proba = baseline_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(\"Baseline F1 Score:\", f1_score(y_valid, y_pred))\n",
    "print(\"Baseline AUC-ROC:\", roc_auc_score(y_valid, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  The baseline model setup is well executed. You correctly split the data with stratification, trained a RandomForest classifier, and evaluated it using both F1 and AUC-ROC metrics. This provides a solid starting point for performance comparison.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.5410628019323671\n",
      "Weighted AUC-ROC: 0.853246158330904\n"
     ]
    }
   ],
   "source": [
    "model_weighted = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "model_weighted.fit(X_train, y_train)\n",
    "\n",
    "y_pred_weighted = model_weighted.predict(X_valid)\n",
    "y_proba_weighted = model_weighted.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(\"Weighted F1 Score:\", f1_score(y_valid, y_pred_weighted))\n",
    "print(\"Weighted AUC-ROC:\", roc_auc_score(y_valid, y_proba_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  You‚Äôve correctly applied class weighting to address class imbalance and evaluated the model using appropriate metrics. This is a valid and well-implemented technique for improving performance on imbalanced data.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "majority = train_data[train_data.Exited == 0]\n",
    "minority = train_data[train_data.Exited == 1]\n",
    "\n",
    "majority_downsampled = majority.sample(len(minority), random_state=42)\n",
    "\n",
    "downsampled = pd.concat([majority_downsampled, minority])\n",
    "X_train_down = downsampled.drop('Exited', axis=1)\n",
    "y_train_down = downsampled['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  You've correctly implemented downsampling to balance the classes in the training set. The approach is clear and reproducible, making it a solid second method for addressing class imbalance.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled F1 Score: 0.5931558935361216\n",
      "Downsampled AUC-ROC: 0.8476149493098646\n"
     ]
    }
   ],
   "source": [
    "model_down = RandomForestClassifier(random_state=42)\n",
    "model_down.fit(X_train_down, y_train_down)\n",
    "\n",
    "y_pred_down = model_down.predict(X_valid)\n",
    "y_proba_down = model_down.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(\"Downsampled F1 Score:\", f1_score(y_valid, y_pred_down))\n",
    "print(\"Downsampled AUC-ROC:\", roc_auc_score(y_valid, y_proba_down))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  The model trained on the downsampled data was implemented correctly, and the evaluation using F1 and AUC-ROC provides a clear comparison with previous approaches. Everything is consistent and well done.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the model's F1 score on the test set and meet the required threshold of 0.59, we applied hyperparameter tuning using `GridSearchCV` on the downsampled dataset.\n",
    "\n",
    "The grid search explored various combinations of:\n",
    "- number of trees)\n",
    "- (maximum depth of each tree)\n",
    "- (minimum number of samples required to split an internal node)\n",
    "- (minimum number of samples required to be at a leaf node)\n",
    "\n",
    "The best model was then evaluated on the test set using both **F1 Score** and **AUC-ROC** to ensure robust performance on imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Final F1 Score (Test Set): 0.5757575757575757\n",
      "Final AUC-ROC (Test Set): 0.8521695809831402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "'n_estimators': [100, 200],\n",
    "'max_depth': [5, 10, 15],\n",
    "'min_samples_split': [2, 5, 10],\n",
    "'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "estimator=RandomForestClassifier(random_state=42),\n",
    "param_grid=param_grid,\n",
    "scoring='f1',\n",
    "cv=5,\n",
    "n_jobs=-1,\n",
    "verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_down, y_train_down)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Final F1 Score (Test Set):\", f1_score(y_test, y_pred_test))\n",
    "print(\"Final AUC-ROC (Test Set):\", roc_auc_score(y_test, y_proba_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Final F1 Score (Test Set): 0.5906040268456376\n",
      "Final AUC-ROC (Test Set): 0.8499146295756465\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "majority = train_data[train_data.Exited == 0]\n",
    "minority = train_data[train_data.Exited == 1]\n",
    "\n",
    "minority_upsampled = minority.sample(len(majority), replace=True, random_state=42)\n",
    "\n",
    "upsampled = pd.concat([majority, minority_upsampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "X_train_up = upsampled.drop('Exited', axis=1)\n",
    "y_train_up = upsampled['Exited']\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "param_grid = {\n",
    "'n_estimators': [100, 200],\n",
    "'max_depth': [5, 10, 15],\n",
    "'min_samples_split': [2, 5, 10],\n",
    "'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "estimator=RandomForestClassifier(random_state=42),\n",
    "param_grid=param_grid,\n",
    "scoring='f1',\n",
    "cv=5,\n",
    "n_jobs=-1,\n",
    "verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_up, y_train_up)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Final F1 Score (Test Set):\", f1_score(y_test, y_pred_test))\n",
    "print(\"Final AUC-ROC (Test Set):\", roc_auc_score(y_test, y_proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 2:</b><br>\n",
    "  Great job applying hyperparameter tuning to improve the model trained on the downsampled data. You're very close ‚Äî the final F1 score on the test set reached 0.57, which shows solid progress but still falls just short of the 0.59 requirement. To improve the score further, consider trying the same hyperparameter tuning approach using an upsampled training set. Here's a suggested setup for upsampling the minority class:\n",
    "  <br><br>\n",
    "  <code>\n",
    "  # Combine features and target<br>\n",
    "  train_data = pd.concat([X_train, y_train], axis=1)<br>\n",
    "  majority = train_data[train_data.Exited == 0]<br>\n",
    "  minority = train_data[train_data.Exited == 1]<br>\n",
    "  minority_upsampled = minority.sample(len(majority), replace=True, random_state=42)<br>\n",
    "  upsampled = pd.concat([majority, minority_upsampled]).sample(frac=1, random_state=42)<br>\n",
    "  X_train_up = upsampled.drop('Exited', axis=1)<br>\n",
    "  y_train_up = upsampled['Exited']\n",
    "  </code>\n",
    "  <br><br>\n",
    "  Then repeat your hyperparameter tuning process using <code>X_train_up</code> and <code>y_train_up</code>. This may help you push the F1 score over the required threshold.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Final testing was completed correctly using the test set. The use of both F1 and AUC-ROC metrics aligns well with the project requirements and provides a clear view of model performance.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  The current F1 score on the test set is slightly below the required threshold of 0.59. To improve it, consider performing hyperparameter tuning on your best-performing model (e.g., using <code>GridSearchCV</code> or <code>RandomizedSearchCV</code>) to find an optimal configuration.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project focused on predicting customer churn for Beta Bank, where ~80% of customers stayed and ~20% churned.\n",
    "Evaluated three modeling strategies:\n",
    "- Baseline model (no balancing)\n",
    "- Class-weighted model\n",
    "- Downsampling of the majority class\n",
    "The best model, trained on the downsampled dataset and tuned using GridSearchCV, achieved:\n",
    "- Validation F1 Score: 0.5932 (Met the requirement)\n",
    "- Test F1 Score: 0.057 (Well below 0.59 threshold)\n",
    "- Test AUC-ROC: 0.852 \n",
    "While the validation set showed promising results, the model failed to generalize effectively on the test set.\n",
    "This indicates potential overfitting or insufficient learning from the minority class. Additional steps like feature engineering, more robust tuning, or ensembling may be needed to improve performance.\n",
    "Despite the low F1 test score, the model shows strong AUC-ROC, suggesting it still separates churn vs. non-churn well ‚Äî a foundation Beta Bank can build on for future churn prevention efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  The conclusion is clearly written and summarizes the modeling approaches and results effectively. It highlights the strength of the downsampled model and the consistent AUC-ROC performance, showing a solid understanding of the task and its goals.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Be careful when interpreting the threshold requirement. The F1 score passed 0.59 on the validation set, but the final F1 on the test set is still below that mark. Consider revising the conclusion after improving the test score through hyperparameter tuning or other enhancements.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
