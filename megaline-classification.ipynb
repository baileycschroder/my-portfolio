{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "\n",
    "**Overall Summary of the Project**\n",
    "\n",
    "Hi Bailey! You‚Äôve done a great job tuning a Random Forest and presenting validation/test accuracy along with classification metrics. Here‚Äôs some feedback, step by step:\n",
    "\n",
    "1. **Introduction & Context**  \n",
    "   - üî¥ *Missing:* Add a brief intro at the top explaining the business goal (recommend Smart vs. Ultra) and the 0.75 accuracy threshold.\n",
    "     \n",
    "   - üìã *Why:* Sets context before launching into code.\n",
    "\n",
    "2. **Data Exploration**  \n",
    "   - ‚úÖ You load and display the first rows with `df.head()`.  \n",
    "   - üîÑ *Suggestion:* Show `df.info()` and `df.describe()` to confirm no missing values, and print `df['is_ultra'].value_counts(normalize=True)` to highlight class balance.\n",
    "\n",
    "3. **Data Splitting**  \n",
    "   <code>\n",
    "   X_temp, X_test, y_temp, y_test = train_test_split(‚Ä¶)  \n",
    "   X_train, X_valid, y_train, y_valid = train_test_split(‚Ä¶)  \n",
    "   </code>  \n",
    "   - ‚úÖ Correct 60/20/20 split with `random_state=42`.  \n",
    "   - üìå *Tip:* Pull these two splits into one consolidated block at the top so all models share the same subsets.\n",
    "\n",
    "4. **Model & Hyperparameter Tuning**  \n",
    "   <code>\n",
    "   grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='accuracy')  \n",
    "   grid_search.fit(X_train, y_train)  \n",
    "   best_model = grid_search.best_estimator_  \n",
    "   </code>  \n",
    "   - ‚úÖ You use `GridSearchCV` to tune `n_estimators`, `max_depth`, and `min_samples_split`.  \n",
    "   - üîç *Suggestion:* Print out `grid_search.best_params_` so readers know exactly which combination was selected.\n",
    "\n",
    "5. **Validation & Test Evaluation**  \n",
    "   <code>\n",
    "   valid_accuracy = accuracy_score(y_valid, valid_preds)  \n",
    "   test_accuracy  = accuracy_score(y_test,  test_preds)  \n",
    "   </code>  \n",
    "   - ‚úÖ You report both validation (79.5%) and test (82.1%) accuracy.  \n",
    "   - üìà *Next step:* Compare against a simple baseline:  \n",
    "     <code>\n",
    "     from sklearn.dummy import DummyClassifier  \n",
    "     dummy = DummyClassifier(strategy='most_frequent')  \n",
    "     dummy.fit(X_train, y_train)  \n",
    "     print('Baseline accuracy:', dummy.score(X_test, y_test))  \n",
    "     </code>  \n",
    "     This shows how much you‚Äôve improved over ‚Äúalways predict Smart.‚Äù\n",
    "\n",
    "6. **Detailed Metrics & Insights**  \n",
    "   <code>\n",
    "   print(classification_report(y_test, test_preds))  \n",
    "   print(confusion_matrix(y_test, test_preds))  \n",
    "   </code>  \n",
    "   - ‚úÖ Great use of precision, recall, and F1.  \n",
    "   - üîÑ *Suggestion:* Comment on what these numbers mean‚Äîe.g., ‚ÄúRecall for Ultra is only 0.54, so about half of the true Ultra users are missed.‚Äù\n",
    "\n",
    "7. **Conclusion & Next Steps**  \n",
    "   - üîÑ *Critical:* Add a closing section that:\n",
    "     1. **Restates** the final test accuracy and best hyperparameters.\n",
    "     2. **Reflects** on model strengths (high Smart-plan accuracy) and weaknesses (Ultra recall).\n",
    "     3. **Proposes** improvements such as class weighting, SMOTE for Ultra class, or trying other models (e.g., XGBoost).\n",
    "\n",
    "---\n",
    "\n",
    "**Overall Summary**\n",
    "\n",
    "- **Strengths:** Solid GridSearch, clear evaluation, and thorough metrics.  \n",
    "- **Opportunities:** Context-setting intro, baseline comparison, deeper discussion of confusion matrix insights, and a richer conclusion with next steps.\n",
    "\n",
    "You‚Äôre on the right track‚Äîthese tweaks will make your report even clearer and more actionable. Keep up the great work! üöÄ \n",
    "\n",
    "---\n",
    "\n",
    "**Status: waiting for changes**\n",
    "\n",
    "Do not hesitate to reach out to me if you have any questions regarding your review :) We are here to help you succeed!\n",
    "\n",
    "**Reviewer: Matias - Discord: mcoustasse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "\n",
    "**Overall Summary of the Project Iter 2**\n",
    "\n",
    "Congrats on your approval, Bailey! ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Megaline, a mobile phone company, noticed that a lot of their customers are still using old plans. They want to figure out which of their newer plans ‚Äî Smart or Ultra ‚Äî would be the best fit for each user based on how they use their phone. In this project, we're building a model that looks at user behavior and predicts whether they should be on the Smart or Ultra plan. It's a binary classification problem, and we‚Äôre aiming for at least **75% accuracy** on the test data to make sure the model‚Äôs reliable. We‚Äôll be using a Random Forest classifier to get the best possible results and will check performance with accuracy and classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7947\n",
      "Test Accuracy: 0.8212\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       455\n",
      "           1       0.78      0.54      0.64       188\n",
      "\n",
      "    accuracy                           0.82       643\n",
      "   macro avg       0.81      0.74      0.76       643\n",
      "weighted avg       0.82      0.82      0.81       643\n",
      "\n",
      "Confusion Matrix:\n",
      "[[427  28]\n",
      " [ 87 101]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "df.head()\n",
    "\n",
    "features = df.drop(columns='is_ultra')\n",
    "target = df['is_ultra']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "valid_preds = best_model.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "test_preds = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, test_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I built a machine learning model to predict whether a Megaline user would switch to the Ultra or Smart plan, based on their monthly call, message, and internet usage. After performing an initial data exploration, I split the dataset into training (60%), validation (20%), and test (20%) sets. I trained a Random Forest Classifier and used GridSearchCV to tune hyperparameters such as `n_estimators`, `max_depth`, and `min_samples_split`. The final model achieved a test accuracy of **82.1%**, exceeding the required threshold of 75%. The model performed especially well on users who stayed on the Smart plan, while classification of Ultra plan users showed room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
